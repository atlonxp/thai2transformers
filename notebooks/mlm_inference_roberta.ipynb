{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import RobertaTokenizerFast, RobertaTokenizer\n",
    "\n",
    "from tokenizers import SentencePieceBPETokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.tokenization_roberta.RobertaTokenizerFast at 0x7f7b02c61f60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"../dataset/spm/th-wiki_only_20.7.2020_small\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.tokenization_roberta.RobertaTokenizer at 0x7f7b02c61ef0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_spm = RobertaTokenizer(\n",
    "                    vocab_file=\"../dataset/spm/th-wiki_only_20.7.2020_small_sentencepiece/vocab.json\",\n",
    "                    merges_file=\"../dataset/spm/th-wiki_only_20.7.2020_small_sentencepiece/merges.txt\")\n",
    "tokenizer_spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_bpe_dict = tokenizer.get_vocab()\n",
    "th_spm_dict = tokenizer_spm.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eries\n",
      "กษาปณ์\n"
     ]
    }
   ],
   "source": [
    "print(list(th_bpe_dict.keys())[10])\n",
    "print(list(th_spm_dict.keys())[20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 1545, 284, 275, 1531, 2], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus('รถไฟสีแดง')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 119, 3, 3, 2]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tokenizer_spm.encode('ส')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_tok(text:str, tokenizer=tokenizer):\n",
    "    out = tokenizer.tokenize(text)\n",
    "\n",
    "    ids = tokenizer.convert_tokens_to_ids(out)\n",
    "    out_txt = '<SEP>'.join([ tokenizer.decode([_id]) for _id in ids ])\n",
    "    print(f'out: {out}')\n",
    "    print(f'Ids: {ids}')    \n",
    "    print(f'Tokens: {out_txt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: ['à¸Ľ', 'à¸µ', 'Ġ', 'Ġà¸Ħ', 'à¹Ī', 'à¸°', 'Ġà¸Ħà¸£', 'à¸±', 'à¸ļ', 'Ġ', 'à¹ĥà¸Ķ', 'Ġà¸ģ', 'à¹ĩ', 'Ġà¸¡', 'à¸µ', 'Ġà¸Ĺ', 'à¸µà¹Ī', 'Ġà¸Ļ', 'à¸µà¹Ī', 'Ġà¸Ļ', 'à¸µà¹ī', 'Ġà¸ļ', 'à¸¸', 'à¸ģ', 'Ġà¸Ĺ', 'à¸¸', 'à¸ģ', 'Ġà¸Ĺ', 'à¸¸', 'à¸ģà¸Ĥ', 'à¹Į']\n",
      "Ids: [296, 275, 225, 386, 269, 283, 913, 271, 288, 225, 1266, 447, 300, 406, 275, 397, 299, 477, 299, 477, 394, 581, 302, 270, 397, 302, 270, 397, 302, 1191, 291]\n",
      "Tokens: ป<SEP>ี<SEP> <SEP> ค<SEP>่<SEP>ะ<SEP> คร<SEP>ั<SEP>บ<SEP> <SEP>ใด<SEP> ก<SEP>็<SEP> ม<SEP>ี<SEP> ท<SEP>ี่<SEP> น<SEP>ี่<SEP> น<SEP>ี้<SEP> บ<SEP>ุ<SEP>ก<SEP> ท<SEP>ุ<SEP>ก<SEP> ท<SEP>ุ<SEP>กข<SEP>์\n"
     ]
    }
   ],
   "source": [
    "viz_tok('ปี  ค่ะ ครับ ใด ก็ มี ที่ นี่ นี้ บุก ทุก ทุกข์')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: ['à¸Ńà¸²à¸£à¸¢à¸ĺà¸£à¸£à¸¡', 'à¹Ĥà¸ļà¸£à¸²à¸ĵ', 'à¸Ĥà¸Ńà¸ĩ', 'à¹ģà¸Ķà¸Ļ', 'à¸ģà¸¥à¸²à¸ĩ']\n",
      "Ids: [9736, 1604, 340, 3611, 713]\n",
      "Tokens: อารยธรรม<SEP>โบราณ<SEP>ของ<SEP>แดน<SEP>กลาง\n"
     ]
    }
   ],
   "source": [
    "viz_tok('อารยธรรมโบราณของแดนกลาง')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: ['à', '¸', 'Ń', 'à', '¸', '²', 'à', '¸', '£', 'à', '¸', '¢', 'à', '¸', 'ĺ', 'à', '¸', '£', 'à', '¸', '£', 'à', '¸', '¡', 'à', '¹', 'Ĥ', 'à', '¸', 'ļ', 'à', '¸', '£', 'à', '¸', '²', 'à', '¸', 'ĵ', 'à', '¸', 'Ĥ', 'à', '¸', 'Ń', 'à', '¸', 'ĩ', 'à', '¹', 'ģ', 'à', '¸', 'Ķ', 'à', '¸', 'Ļ', 'à', '¸', 'ģ', 'à', '¸', '¥', 'à', '¸', '²', 'à', '¸', 'ĩ']\n",
      "Ids: [119, 3, 3, 119, 3, 3, 119, 3, 102, 119, 3, 101, 119, 3, 3, 119, 3, 102, 119, 3, 102, 119, 3, 100, 119, 3, 3, 119, 3, 3, 119, 3, 102, 119, 3, 3, 119, 3, 3, 119, 3, 3, 119, 3, 3, 119, 3, 3, 119, 3, 3, 119, 3, 3, 119, 3, 3, 119, 3, 3, 119, 3, 3, 119, 3, 3, 119, 3, 3]\n",
      "Tokens: �<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP>�<SEP>�<SEP><unk><SEP>�<SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP>�<SEP>�<SEP><unk><SEP>�<SEP>�<SEP><unk><SEP>�<SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP>�<SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk><SEP>�<SEP><unk><SEP><unk>\n"
     ]
    }
   ],
   "source": [
    "viz_tok('อารยธรรมโบราณของแดนกลาง', tokenizer=tokenizer_spm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"../results/checkpoint-25000/\",\n",
    "    tokenizer=tokenizer,\n",
    "    device=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '<s>อารยธรรมรถัฟ้า</s>',\n",
       "  'score': 0.06177940219640732,\n",
       "  'token': 271,\n",
       "  'token_str': 'à¸±'},\n",
       " {'sequence': '<s>อารยธรรมรถิฟ้า</s>',\n",
       "  'score': 0.04437718912959099,\n",
       "  'token': 279,\n",
       "  'token_str': 'à¸´'},\n",
       " {'sequence': '<s>อารยธรรมรถ้ฟ้า</s>',\n",
       "  'score': 0.04331345111131668,\n",
       "  'token': 274,\n",
       "  'token_str': 'à¹ī'},\n",
       " {'sequence': '<s>อารยธรรมรถ่ฟ้า</s>',\n",
       "  'score': 0.04146899655461311,\n",
       "  'token': 269,\n",
       "  'token_str': 'à¹Ī'},\n",
       " {'sequence': '<s>อารยธรรมรถีฟ้า</s>',\n",
       "  'score': 0.037992678582668304,\n",
       "  'token': 275,\n",
       "  'token_str': 'à¸µ'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(\"อารยธรรมรถ<mask>ฟ้า\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
